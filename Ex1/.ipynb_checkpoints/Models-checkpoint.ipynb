{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For XA1 we have 6 features, mse = 2.8376079804827845 and r2 = 0.09149507625925025.\n",
      "For XA2 we have 100 features, mse = 2.261646099920115 and r2 = 0.35904243817815534.\n",
      "For XB1 we have 100 features, mse = 3.5305085152346094 and r2 = 0.26349570197401173.\n",
      "For XB2 we have 100 features, mse = 3.5305085152346094 and r2 = -0.0005119410457692264.\n"
     ]
    }
   ],
   "source": [
    "## imporing data\n",
    "\n",
    "import numpy as np\n",
    "data = np.load(\"exercise1.npz\")\n",
    "XA1 = data['XA1']\n",
    "yA1 = data['yA1']\n",
    "XA2 = data['XA2']\n",
    "yA2 = data['yA2']\n",
    "\n",
    "XB1 = data['XB1']\n",
    "yB1 = data['yB1']\n",
    "XB2 = data['XB2']\n",
    "yB2 = data['yB2']\n",
    "data.close()\n",
    "\n",
    "## selecting featues \n",
    "XA1_features = [7, 6, 9, 3, 2, 4]\n",
    "XA2_features = [7, 9, 3, 6, 4, 8]\n",
    "XB1_features = [352,599,188,681,283,44,386,407,332,167,171,12,77,646,7,732,117,478,754,289,233,43,252,676,747,424,760,361]\n",
    "XB2_features = [20,737,541,258,144,718,233,388,433,357,425,664,548,621,499,606,568,413,530,218,482,107,786,592,292,184,223,434,424,199,31,\n",
    " 656,87,317,522,555,634,616,38,649,265,384,18,206,269,782,565,304,439,366,417,219,200,180,65,597,145,583,202,444,50,364,476,\n",
    " 209,159,710,536,109,338,447,700,716,339,380,44,540,395,509,743,405,665,211,114,22,774,556,722,771,721,259,372,783,69,182,\n",
    " 643,352,210,40,148,49]\n",
    "\n",
    "XA1_filt = XA1[:,XA1_features]\n",
    "XA2_filt = XA2[:,XA2_features]\n",
    "XB1_filt = XB1[:,XB1_features]\n",
    "XB2_filt = XB2[:,XB1_features]\n",
    "\n",
    "## initialice performance measure model\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def evaluate_performance(X,y,cv_):\n",
    "    reg = linear_model.LinearRegression()\n",
    "    cv_results = cross_validate(reg, X, y, cv=cv_, scoring=('r2','neg_mean_squared_error'))\n",
    "    sorted(cv_results.keys())\n",
    "    ['fit_time', 'score_time', 'test_score']\n",
    "    test_mean_squared_error = -np.mean(cv_results['test_neg_mean_squared_error'])\n",
    "    test_r2 = np.mean(cv_results['test_r2'])\n",
    "    return test_mean_squared_error, test_r2\n",
    "\n",
    "## performing evaluation test \n",
    "\n",
    "mse_AX1, r2_AX1 = evaluate_performance(XA1_filt, yA1, 10);\n",
    "mse_AX2, r2_AX2 = evaluate_performance(XA2_filt, yA2, 10);\n",
    "mse_BX1, r2_BX1 = evaluate_performance(XB1_filt, yB1, 10);\n",
    "mse_BX2, r2_BX2 = evaluate_performance(XB2_filt, yA2, 10);\n",
    "\n",
    "## printing the results \n",
    "\n",
    "print(\"For XA1 we have \" + str(len(XA1_features)) + \" features, mse = \" + str(mse_AX1) + \" and r2 = \" + str(r2_AX1) + \".\")\n",
    "print(\"For XA2 we have \" + str(len(XBA_features)) + \" features, mse = \" + str(mse_AX2) + \" and r2 = \" + str(r2_AX2) + \".\")\n",
    "print(\"For XB1 we have \" + str(len(XB1_features)) + \" features, mse = \" + str(mse_BX2) + \" and r2 = \" + str(r2_BX1) + \".\")\n",
    "print(\"For XB2 we have \" + str(len(XB2_features)) + \" features, mse = \" + str(mse_BX2) + \" and r2 = \" + str(r2_BX2) + \".\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
